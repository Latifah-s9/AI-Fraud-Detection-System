import streamlit as st
import pandas as pd
import numpy as np
import joblib
import shap
import plotly.express as px
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import os

st.set_page_config(page_title="AI Fraud Detection System", page_icon="ğŸ’³ğŸ›¡ï¸", layout="wide")
st.title("ğŸ’³ğŸ›¡ï¸ AI Fraud Detection System")

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
try:
    model = joblib.load("model.pkl")
except Exception:
    st.error("âŒ model.pkl not found â€” run train_model.py first.")
    st.stop()

# Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨
def get_trained_features(m):
    try:
        return m.get_booster().feature_names
    except Exception:
        return None

TRAINED = get_trained_features(model)
FALLBACK = [f"V{i}" for i in range(1, 29)] + ["Amount"]

# ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø§Ø®ØªÙ„Ø§ÙØ§Øª
def align_columns(raw_df):
    df = raw_df.copy()
    lower_map = {c.lower(): c for c in df.columns}
    want = TRAINED if TRAINED else FALLBACK
    use_cols = []
    for c in want:
        lc = c.lower()
        if lc in lower_map:
            use_cols.append(lower_map[lc])
        else:
            df[c] = 0
            use_cols.append(c)
    extra = [c for c in df.columns if c not in use_cols and c.lower() not in {w.lower() for w in want}]
    df = df[use_cols]
    return df, extra

uploaded = st.file_uploader("ğŸ“‚ Upload transactions CSV", type="csv")

if uploaded is not None:
    try:
        data_in = pd.read_csv(uploaded)
        st.subheader("ğŸ‘€ Data Preview")
        st.dataframe(data_in.head())

        X, extras = align_columns(data_in)
        if extras:
            st.info(f"Ignored extra columns: {extras}")

        # ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        if hasattr(model, "predict_proba"):
            prob = model.predict_proba(X)[:, 1]
            pred = (prob >= 0.5).astype(int)
            X_out = data_in.copy()
            X_out["Fraud_Probability"] = prob
            X_out["Prediction"] = pred
        else:
            pred = model.predict(X)
            X_out = data_in.copy()
            X_out["Prediction"] = pred

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¹Ø§Ù…Ø©
        c1, c2, c3 = st.columns(3)
        with c1: st.metric("Total", len(X_out))
        with c2: st.metric("Fraudulent", int((X_out["Prediction"] == 1).sum()))
        with c3: st.metric("Normal", int((X_out["Prediction"] == 0).sum()))

        # Ø±Ø³Ù… Ø§Ù„ØªÙˆØ²ÙŠØ¹
        fig = px.histogram(X_out, x="Prediction", title="ğŸ“Š Prediction Distribution")
        st.plotly_chart(fig, use_container_width=True)

        # ğŸ” ØªØ­Ù„ÙŠÙ„ SHAP Ù„Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ (Ù…ÙØ­Ø¯Ø« Ø¨Ø§Ù„ÙƒØ§Ù…Ù„)
        try:
            st.subheader("ğŸ” Feature Importance (SHAP Analysis)")
            sample = X.sample(min(500, len(X)), random_state=42)

            shap_values = None
            explainer = None

            # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£Ø­Ø¯Ø« (ØªØ¹Ù…Ù„ Ù…Ø¹ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¥ØµØ¯Ø§Ø±Ø§Øª)
            try:
                explainer = shap.Explainer(model, sample)
                shap_values = explainer(sample)
            except Exception:
                # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© (Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ Ø¥ØµØ¯Ø§Ø±Ø§Øª XGBoost Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©)
                try:
                    explainer = shap.TreeExplainer(model)
                    shap_values = explainer.shap_values(sample)
                except Exception:
                    shap_values = None

            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙ‚Ø· Ø¥Ø°Ø§ ØªÙ… Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ù†Ø¬Ø§Ø­
            if shap_values is not None:
                st.info("âœ… SHAP Analysis computed successfully.")
                shap.summary_plot(shap_values, sample, plot_type="bar", show=False)
                st.pyplot(bbox_inches="tight", clear_figure=True)
                plt.clf()
            else:
                st.warning("âš ï¸ SHAP could not interpret this model automatically.")

        except Exception as e:
            st.info(f"âš ï¸ SHAP safely skipped: {str(e)}")

        # Performance metrics: ØªØ¸Ù‡Ø± ÙÙ‚Ø· ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ± (Colab Ø£Ùˆ Jupyter)
        is_dev = any(env in os.getcwd().lower() for env in ["colab", "notebook", "jupyter"])
        if is_dev and "Class" in data_in.columns:
            try:
                y_true = pd.to_numeric(data_in["Class"], errors="coerce").fillna(0).astype(int)
                acc = accuracy_score(y_true, pred)
                pre = precision_score(y_true, pred, zero_division=0)
                rec = recall_score(y_true, pred, zero_division=0)
                f1 = f1_score(y_true, pred, zero_division=0)
                st.caption(f"ğŸ“ˆ Accuracy={acc:.4f} | Precision={pre:.4f} | Recall={rec:.4f} | F1={f1:.4f}")
            except Exception:
                pass

        # Ø²Ø± Ù„ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        csv = X_out.to_csv(index=False).encode("utf-8")
        st.download_button("â¬‡ï¸ Download Predictions", csv, "predictions.csv", "text/csv")

    except Exception as e:
        st.error("âŒ Error while processing the file.")
        st.text(str(e))
else:
    st.info("ğŸ“¤ Upload a CSV file to start predictions.")
